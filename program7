
[7]: #7.Write a program to demonstrate Regression analysis with residual plots on a given data s import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Linear Regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
# If you have your own CSV, uncomment this and comment the synthetic dataset block
# data = pd.read_csv("regression_dataset.csv")
# Generate synthetic dataset for demonstration
np.random.seed(42)
X = np.random.rand(100, 1) * 10 # Features between 0 and 10
y = 3.5 X. flatten() + np.random.randn(100) 5+ 10 # Linear with noise
data = pd.DataFrame({'X': X.flatten(), 'Y': y})
# Split dataset
X = data[[ 'X']]
y = data['Y']
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
#Train model
model = LinearRegression()
model.fit(X_train, y_train)
=
y_pred model.predict(X_test)
#Regression Line Plot
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.scatter (X_test, y_test, color='blue', label='Actual') plt.plot(X_test, y_pred, color='red', label='Predicted Line') plt.title("Linear Regression Fit")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend()
#Residual Plot
residuals = y_test
plt.subplot(1, 2, 2)
y_pred
plt.scatter (y_pred, residuals, color='purple')
plt.axhline(0, color='gray', linestyle='--')
plt.title("Residual Plot")
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.tight_layout()
plt.show()
# Print evaluation
print("Model Coefficient (Slope):", model.coef_[0])
print("Model Intercept: ", model.intercept_)
print("R2 Score:", r2_score (y_test, y_pred))
print("Mean Squared Error:", mean_squared_error (y_test, y_pred))